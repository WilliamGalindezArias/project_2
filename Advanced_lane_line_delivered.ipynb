{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions_2 as hf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "objpoints, imgpoints = hf.calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = hf.image_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Undistort the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "undistorted_ones = []\n",
    "for each_image in test_images:\n",
    "    undistorted_one = hf.undistort(each_image, objpoints, imgpoints)\n",
    "    undistorted_ones.append(undistorted_one)\n",
    "\n",
    "# I have all the images now in undistorted ones array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Processing : Color selection, gradients,  perspective transform and Polynomial Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image):\n",
    "    # 1. The channel Selector\n",
    "    h,l,s = hf.hls_selector(image)\n",
    "    \n",
    "    #2. the Color Thresholding\n",
    "    color = hf.color_threshold(s, color_t=(170,255))\n",
    "    \n",
    "    #3. The gradients and its thresholds\n",
    "    sobely = hf.sobel_y(s, thresh_min=40, thresh_max=255)\n",
    "    sobelx = hf.sobel_x(s, thresh_min=10, thresh_max=100)\n",
    "    \n",
    "    #4. Combination Of binary outputs\n",
    "    combined = np.zeros_like(sobelx)\n",
    "    combined = np.dstack(( sobely, color, sobelx))*255\n",
    "    \n",
    "    #5. Perspective Transform\n",
    "    warped_image, m_inv = hf.perspective_transform(combined)\n",
    "    \n",
    "    #6. Logic for Polynomial processing\n",
    "    \n",
    "    left_fitx, right_fitx, ploty, left_pos, right_pos = hf.fit_polynomial(warped_image)\n",
    "    \n",
    "    \n",
    "    out_img = hf.draw_lines(warped_image, image, m_inv, left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    left_line.radius_of_curvature_meters = int(hf.measure_curvature_real()[0])\n",
    "    right_line.radius_of_curvature_meters = int(hf.measure_curvature_real()[1])\n",
    "    avg_curv = (left_line.radius_of_curvature_meters + right_line.radius_of_curvature_meters) // 2\n",
    "    \n",
    "    curv_s = 'Radius of Curvature = {}(m)'.format(avg_curv)\n",
    "    cv2.putText(out_img, curv_s, (30,60), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255))\n",
    "    \n",
    "    center_car = image.shape[1] // 2\n",
    "    \n",
    "    l_c = int(right_pos - left_pos)\n",
    "    offset = (l_c - center_car) * (3.7/700)\n",
    "    \n",
    "    \n",
    "    if (offset > 0):\n",
    "        offset_string = 'Vehicle is {0:.2f}m left of center'.format(offset)\n",
    "    else:\n",
    "        offset_string = 'Vehicle is {0:.2f}m right of center'.format(np.absolute(offset))\n",
    "        \n",
    "    cv2.putText(out_img, offset_string, (20, 120), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255))\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/video_test4.mp4\n",
      "[MoviePy] Writing video output_images/video_test4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [05:02<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/video_test4.mp4 \n",
      "\n",
      "CPU times: user 2min 29s, sys: 26.4 s, total: 2min 56s\n",
      "Wall time: 5min 5s\n"
     ]
    }
   ],
   "source": [
    "vid_output = 'output_images/video_test4.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip.fl_image(pipeline) \n",
    "%time white_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_images/video_test4.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
